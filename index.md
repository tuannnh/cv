---
layout: cv
title: Tuan_Nguyen_Resume
---

# Tuan Nguyen  

Discoverer \| Handicrafter \| Data Guru  
Address: TanPhu, Ho Chi Minh  
Mobile/Chat: (+84)904035003  

<!-- ![Badge](https://img.shields.io/badge/GitHub-Pro%20%20%20-blue)&nbsp;![Badge](https://img.shields.io/badge/GitHub-Arctic%20Code%20Vault%20Contributor-orange) -->

<!-- <div id=webaddress>
    <a href="mailto:mail@hungtuan.me" target="blank">
    <img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/gmail.svg" alt="mail@hungtuan.me" height="40" width="40"/></a>
    <a href="https://github.com/tuannnh" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg" alt="discovertuannguyen" height="40" width="40"></a>
    <a href="https://linkedin.com/in/tuannnh" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/linkedin.svg" alt="discovertuannguyen" height="40" width="40"/></a>
    <a href="https://fb.com/supercodingninja" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/facebook.svg" alt="bi.lucius" height="40" width="40"></a>
</div> -->

<div id="webaddress">
  <a href="https://hungtuan.me" target="blank"><i class="fas fa-home"></i> https://hungtuan.me</a> - 
  <a href="mailto:mail@hungtuan.me" target="blank"><i class="fas fa-envelope"></i> mail@hungtuan.me</a> <br>
  <a href="https://github.com/tuannnh" target="blank"><i class="fab fa-github"></i> Tuan Nguyen</a> - 
  <a href="https://www.linkedin.com/in/tuannnh/" target="blank"><i class="fab fa-linkedin"></i> Tuan Nguyen</a> - 
   <a href="https://facebook.com/bi.lucius" target="blank"><i class="fab fa-facebook"></i> Tuan Nguyen</a>
</div>

## Introduction

<!-- Hello. I am Tuan, and I want to enjoy my own world   -->
He has an extraordinary passion for discovering new things  
He addicted to programming, cooking, and doing handicrafts  
<!-- Responsibility and reliability come first  
Easy-going and people supporting enthusiast -->

## Currently

As a Senior Data Engineer with more than 5 years in IT industry experience. His primary responsibilities are helping build ETL pipelines, including modeling, collecting, processing, and provisioning data  
Apart from his daily activities, He also help other operational teams with making automation tools to enhance the business working performance

## Skills

_Data Engineering_

- Extract data from various multiple data sources like: Remote Object Storage (Amazon S3), SFTP, relational databases, non-relational databases, Facebook Analytics, Google Analytics, social media contents, APIs, etc...
- Process many types of data: transactional data, high volume data, user events, logs
- Perform data transformation, masterizing data, data cleaning, data validation
- Build data pipeline for Batch and Stream processing
- Schedule data pipeline jobs orchestration using GoodData, Apache Airflow
- Design data model for data digestion

_Data Analytics_

- Design data model for analytics using Star schema, Snowflake schema
- Apply analytics queries to calculate business metrics
- Create interactive reports and dashboards

_Data Operations_
- Set up development, staging and production environment for data flows
- Implement and integrate client single sign-on authentication and authorization, data mart provisioning
- Config network rules, identity management on cloud
- Monitor and mantain jobs
- Apply automation trigger workflows

_Project Management_
- Follow Agile and SCRUM software development process
- Use versioning control to store and maintain source
- Prepare technical and non-technical documentation, training material for knowledge transfering to client
- Manage projects and tasks on JIRA. Track working progress and performance on Workfront

**Technical**

- Programming languages: Javascript, Ruby, Python
- Database: TiDB, Vertica, PostgreSQL, BigQuery
- Containerization: Docker
- Bash: Shell script, CLI commands
- Version control: Github
- ETL Tools: Apache Airflow, Talend, GoodData, Apache Nifi
- Streaming data: HDFS, Hadoop, Apache Spark, Apache Kafka
- Cloud services: AWS (S3, EC2, IAM, VPC, Lambda), Azure (Active Directory, Function App, ServiceBus, DataBricks, CloudStorage)
- BI Tools: GoodData, PowerBI, Looker Studio

**Others**

- Scheduling and managing tasks for the highest productivity
- Design technical courses for training team members or end-users (clients) 
- Self-learning, researching technical problems and solutions
- Work well in a multicultural office environment 

## Experience

`Oct 2024 - Present`
_Knorex | Sr. Data Engineer_ 

**Product: Digital Marketing Platform**  
Maintain, optimize the data processing and reporting services for customer success
- Design and optimize data model for high scalability
- Develop new features with AI enablement for Report and Analysis service
- Support DevOps on Cloud Migration


`Jan 2020 - Sep 2024`
_KMS Solutions | Sr. Data Engineer_ 

**Project: GoodData's client**  
Design and build data solutions for GoodData's clients in various industries such as: Education, financial services, customer satisfication, retail, multimedia
- Design logical data model based on business intelligence analysis requirements using star schema
- Design and build ETL pipeline for centralizing/mastering data in the data warehouse using GoodDataSDK, GoodData Cloud Native
- Implement multiple types of connectors/downloaders/extractors to connect and collect data from various data sources using Ruby, Python
- Build up automation tools to configure processes and perform API calls for data management using shell script, programing languages
- Config processes integrations with client's system on multiple cloud like SSO SAML, networking connections, data security in AWS, Azure, Google Cloud Platform
- Consulting/training/mentoring data solutions for team members/clients with self-service operations
- Support client's business critical operations on demands via JIRA tickets
- Build reports, dashboards using Analytical Queries, MAQL

**Project: F&B SAAS Client**  
Support client on technical operations with Product Analytics using Mixplanel
- Maintain and optimize data pipeline of user activities event data tracked from product/application to Mixpanel and Google BigQuery
- Support building product analysis reports using Insights, Funnels, Retentions and Flows reporting

**Project: Financial & Banking Client**  
Build data solution POC for a Financial client base on financial data. Target to have risk analysis, debt collection performance analysis
- Build ETL pipeline to extract data from the client's Oracle database, centralize data in Vertica that hosted on Amazon EC2 Instance. Used Talend Studio for ETL jobs
- Schedule cron and monitor jobs run in Linux Management Console server hosted on AWS EC2 using Shell scripts and Apache Airflow
- Utilize SQL for data transformation and leverage In-database Machine Learning Functions to train models and make Risk predictions
- Establish a connection to the database system and create dynamic reports and interactive dashboards for analyzing debt collection performance and gaining insights into customer background criteria

**Project: Banking Business/Services Client**  
Build automated flows to digest data from multiple applications data/vendors sources to data warehouse, capture data changes, then return model for reporting and analytical purposes
- Build ETL pipeline to digest data from banking services and application using Apache Nifi
- Optimize flows for handling large size data files
- Set up integration with SMS/Email providers to handle notification requests on data changes

**Project: Insurance Service Client**  
Build an event-driven Python based Parametric Engine that can use weather and satellite data to evaluate insurance claim check.
- Azure Functions and Kubernectes for application deployment
- Design and maintain application structure with best practice API design (OpenAPI)
- Enable application to align with 12 factors methodlogy in microservices
- Prepare unit tests, performance test
- Utilize Azure Service Bus for message-queue communication between functional steps
- Data store and retrieve using Azure Blob Storage
- Employed pipeline using Azure DataBricks, Delta Lake
- Integrate with current microservices system, CI/CD flows (Sonar cloud, dependabots,...)

`Jan 2019 - Feb 2020`
_Freelance | Full Stack Developer_  
- Design, implement and maintain the Football Booking System based on the customer's requirements  
- Technical stack:
    * Ubuntu cloud, docker
    * Java spring boot
    * JWT Authentication SSO
    * RestfulAPI
    * MySQL, Redis
    * Website dashboard: ReactJS - Mobile: React Native
- Team size: 3 members

`2015 - 2017`
_English Tutor_
- Take responsibility for teaching English in a class of 5 - 10 high school students

## Education

`2012 - 2015`
**University of Finance and Marketing**

- BEc, Finance of Insurance and Investment

`2016 - 2021`
**FPT University**

- B.Eng., Software Engineering

## Certifications

_[IBM Data Engineering Professional Certificates](https://coursera.org/share/af3f2be7ed42d1f98428c5d2f508c714)_

_[AWS Fundamentals SpecializationAWS Fundamentals Specialization](https://www.coursera.org/account/accomplishments/specialization/certificate/V76QLZVD2ZNX)_

_[Build a Data Warehouse in AWS](https://coursera.org/share/4eb6d36dab7767b017c30fbbfa6d8a86)_

_[Mixpanel Partner Certification](https://verify.skilljar.com/c/p5t24qwt74pq)_

_[Project Management Principles and PracticesProject Management Principles and Practices](https://www.coursera.org/account/accomplishments/specialization/certificate/Y63G6CJ3BT55)_


## Awards

`2016`
_Top 2 | Final Round | Softskills Traning Program_, Level Up - Sponsored by Samsung

`2021`
_Professional Growth Award_, recognized by Data and Analytics Department, KMS  Solutions

`2022`
_Certificate Of Appreciation_, Techcon Organizer, KMS Group

## Publications

### Blog articles

`2022`
**[Bring Your Product to a Higher Level with Product Analytics](https://blog.kms-solutions.asia/bring-your-product-to-a-higher-level-with-product-analytics)**

- A blog article to introduce product analytics and how it can help accelerate the business growth
- Published on Dec 1st, 2022

### Webinars

`2022`
**[Webinar | Optimize Customer Journey with Product Analytics](https://info.kms-solutions.asia/optimize-customer-journey-with-product-analytics)**

- An English-based webinar to share how to discover why Product Analytics is essential to your business and how to take advantage of it to improve the customer journey
- Organized on Dec 6th, 2022

<h3 align="right">Last updated: Feb 2025</h3>

<!-- <span align="center"><b><a href="https://hungtuan.me">#DiscoverTuanNguyen</a></b></span>  -->
