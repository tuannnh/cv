---
layout: cv
title: Tuan_Nguyen_Resume
---

# Tuan Nguyen  

Discoverer \| Handicrafter \| Data Engineer  
Address: TanPhu, Ho Chi Minh  
Mobile/Chat: (+84)904035003  

<!-- ![Badge](https://img.shields.io/badge/GitHub-Pro%20%20%20-blue)&nbsp;![Badge](https://img.shields.io/badge/GitHub-Arctic%20Code%20Vault%20Contributor-orange) -->

<!-- <div id=webaddress>
    <a href="mailto:mail@hungtuan.me" target="blank">
    <img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/gmail.svg" alt="mail@hungtuan.me" height="40" width="40"/></a>
    <a href="https://github.com/tuannnh" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg" alt="discovertuannguyen" height="40" width="40"></a>
    <a href="https://linkedin.com/in/tuannnh" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/linkedin.svg" alt="discovertuannguyen" height="40" width="40"/></a>
    <a href="https://fb.com/supercodingninja" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/facebook.svg" alt="bi.lucius" height="40" width="40"></a>
</div> -->

<div id="webaddress">
  <a href="https://hungtuan.me" target="blank"><i class="fas fa-home"></i> https://hungtuan.me</a> - 
  <a href="mailto:mail@hungtuan.me" target="blank"><i class="fas fa-envelope"></i> mail@hungtuan.me</a> <br>
  <a href="https://github.com/tuannnh" target="blank"><i class="fab fa-github"></i> Tuan Nguyen</a> - 
  <a href="https://www.linkedin.com/in/tuannnh/" target="blank"><i class="fab fa-linkedin"></i> Tuan Nguyen</a> - 
   <a href="https://facebook.com/bi.lucius" target="blank"><i class="fab fa-facebook"></i> Tuan Nguyen</a>
</div>

## Introduction

<!-- Hello. I am Tuan, and I want to enjoy my own world   -->
I have an extraordinary passion for discovering new things  
I Love programming, cooking, and doing handicrafts  
<!-- Responsibility and reliability come first  
Easy-going and people supporting enthusiast -->

## Currently

As a Data Engineer with more than 5 years in IT industry experience. My primary responsibilities are helping build ETL pipelines, including modeling, collecting, processing, and provisioning data  
Apart from my daily activities, I also help other operational teams with making automation tools to enhance the business working performance  
Seeking to face any challenges or problems. Feel free to reach out to me. I am glad to hear a ring from you

## Skills

_Data Engineering_

- Extract data from various multiple data sources like: Remote Object Storage (Amazon S3), SFTP, relational databases, non-relational databases, Facebook Analytics, Google Analytics, social media contents, APIs, etc...
- Process many types of data: transactional data, high volume data, user events, logs
- Perform data transformation, masterizing data, data cleaning, data validation
- Build data pipeline for Batch and Stream processing
- Schedule data pipeline jobs orchestration using GoodData, Apache Airflow
- Design data model for data digestion

_Data Analytics_

- Design data model for analytics using Star schema, Snowflake schema
- Apply analytics queries to calculate business metrics
- Create interactive reports and dashboards

_Data Operations_
- Set up development, staging and production environment for data flows
- Implement and integrate client single sign-on authentication and authorization, data mart provisioning
- Config network rules, identity management on cloud
- Monitor and mantain jobs
- Apply automation trigger workflows

_Project Management_
- Follow Agile and SCRUM software development process
- Use versioning control to store and maintain source
- Prepare technical and non-technical documentation, training material for knowledge transfering to client
- Manage projects and tasks on JIRA. Track working progress and performance on Workfront

**Technical**

- Programming languages: Javascript, Ruby, Python
- Database: Vertica, PostgreSQL, BigQuery
- Containerization: Docker
- Bash: Shell script, CLI commands
- Version control: Github
- ETL Tools: Apache Airflow, Talend, GoodData
- Streaming data: HDFS, Hadoop, Apache Spark, Apache Kafka
- Cloud services: AWS (S3, EC2, IAM, VPC, Lambda), Azure (Active Directory, Function App, ServiceBus)
- BI Tools: GoodData, PowerBI, Looker Studio

**Others**

- Scheduling and managing tasks for the highest productivity
- Design technical courses for training team members or end-users (clients) 
- Self-learning, researching technical problems and solutions
- Work well in a multicultural office environment 

## Experience

`2020 - Present`
_KMS Solutions | Sr. Data Engineer_ 

**Project: GoodData's client**  
Design and build data solutions for GoodData's clients in various industries such as: Education, financial services, customer satisfication, retail, multimedia
- Design logical data model based on business intelligence analysis requirements using star schema
- Design and build ETL pipeline for centralizing/mastering data in the data warehouse using GoodDataSDK, GoodData Cloud Native
- Implement multiple types of connectors/downloaders/extractors to connect and collect data from various data sources using Ruby, Python
- Build up automation tools to configure processes and perform API calls for data management using shell script, programing languages
- Config processes integrations with client's system on multiple cloud like SSO SAML, networking connections, data security in AWS, Azure, Google Cloud Platform
- Consulting/training/mentoring data solutions for team members/clients with self-service operations
- Support client's business critical operations on demands via JIRA tickets
- Build reports, dashboards using Analytical Queries, MAQL

**Project: F&B SAAS Client**  
Support client on technical operations with Product Analytics using Mixplanel
- Maintain and optimize data pipeline of user activities event data tracked from product/application to Mixpanel and Google BigQuery
- Support building product analysis reports using Insights, Funnels, Retentions and Flows reporting

**Project: Financial & Banking Client**  
Build data solution POC for a Financial client base on financial data. Target to have risk analysis, debt collection performance analysis
- Build ETL pipeline to extract data from the client's Oracle database, centralize data in Vertica that hosted on Amazon EC2 Instance. Used Talend Studio for ETL jobs
- Schedule cron and monitor jobs run in Linux Management Console server hosted on AWS EC2 using Shell scripts and Apache Airflow
- Utilize SQL for data transformation and leverage In-database Machine Learning Functions to train models and make Risk predictions
- Establish a connection to the database system and create dynamic reports and interactive dashboards for analyzing debt collection performance and gaining insights into customer background criteria

**Project: Insurance Service Client**  
Build an event-driven Python based Parametric Engine that can use weather and satellite data to evaluate insurance claim check.
- Use Azure Functions and Microservices for application deployment
- Design and maintain application structure with best practice API design (OpenAPI)
- Enable application to align with 12 factors methodlogy in microservices
- Prepare unit tests, performance test
- Utilize Azure Service Bus for message-queue communication between functional steps
- Data store and retrieve using Azure Blob Storage 
- Integrate with current microservices system, CI/CD flows (Sonar cloud, dependabots,...)

`2019 - 2020`
_Freelance | Full Stack Developer_  
- Design, implement and maintain the Football Booking System based on the customer's requirements  
- Technical stack:
    * Ubuntu cloud, docker
    * Java spring boot
    * JWT Authentication SSO
    * RestfulAPI
    * MySQL, Redis
    * Website dashboard: ReactJS - Mobile: React Native
- Team size: 3 members

`2015 - 2017`
_English Tutor_
- Take responsibility for teaching English in a class of 5 - 10 high school students

## Education

`2012 - 2015`
**University of Finance and Marketing**

- BEc, Finance of Insurance and Investment

`2016 - 2021`
**FPT University**

- B.Eng., Software Engineering

## Certifications

_[AWS Fundamentals SpecializationAWS Fundamentals Specialization](https://www.coursera.org/account/accomplishments/specialization/certificate/V76QLZVD2ZNX)_

_[Modern Application Development with Java on AWS](https://www.coursera.org/account/accomplishments/specialization/certificate/X2KLVXPK9GTV)_

_[MixpanelPartner Certification](https://verify.skilljar.com/c/p5t24qwt74pq)_

_[Project Management Principles and PracticesProject Management Principles and Practices](https://www.coursera.org/account/accomplishments/specialization/certificate/Y63G6CJ3BT55)_

## Awards

`2016`
_Top 2 | Final Round | Softskills Traning Program_, Level Up - Sponsored by Samsung

`2021`
_Professional Growth Award_, recognized by Data and Analytics Department, KMS  Solutions

`2022`
_Certificate Of Appreciation_, Techcon Organizer, KMS Group

## Publications

### Blog articles

`2022`
**[Bring Your Product to a Higher Level with Product Analytics](https://blog.kms-solutions.asia/bring-your-product-to-a-higher-level-with-product-analytics)**

- A blog article to introduce product analytics and how it can help accelerate the business growth
- Published on Dec 1st, 2022

### Webinars

`2022`
**[Webinar | Optimize Customer Journey with Product Analytics](https://info.kms-solutions.asia/optimize-customer-journey-with-product-analytics)**

- An English-based webinar to share how to discover why Product Analytics is essential to your business and how to take advantage of it to improve the customer journey
- Organized on Dec 6th, 2022

<h3 align="right">Last updated: Mar 2024</h3>

<span align="center"><b><a href="https://hungtuan.me">#DiscoverTuanNguyen</a></b></span>
